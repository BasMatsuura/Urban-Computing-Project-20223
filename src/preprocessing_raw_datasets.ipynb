{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### Import Libraries ###\n",
    "########################\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjacency Matrix of Dutch Municipalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "### Load ShapeFile Municipalities ###\n",
    "#####################################\n",
    "\n",
    "# Adjacency is based on a ShapeFile from the CBS: https://www.cbs.nl/nl-nl/dossier/nederland-regionaal/geografische-data/wijk-en-buurtkaart-2020\n",
    "\n",
    "path_cbs_municipality_shapefile = r'C:\\Users\\matsu\\Desktop\\Universiteit\\MSc Statistics & Data Science\\Year 3\\Semester 1\\Mandatory Courses\\Urban Computing\\Project\\Code\\Cloned Repositories\\EpiGNN\\data\\WijkBuurtkaart_2020_v3\\gemeente_2020_v3.shp'\n",
    "\n",
    "# Load the shapefile\n",
    "gdf = gpd.read_file(path_cbs_municipality_shapefile)\n",
    "\n",
    "# Remove duplicate municipalities where H2O is included. Also remove the small Belgian enclave in Noord-Brabant.\n",
    "gdf = gdf[(gdf['H2O'] != 'JA') & (gdf['H2O'] != 'B')]\n",
    "gdf = gdf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### Create Adjacency Matrix ###\n",
    "###############################\n",
    "\n",
    "adjacency_dict = {}\n",
    "\n",
    "for i, municipality_i in gdf.iterrows():\n",
    "    adjacent_municipalities = []\n",
    "    for j, municipality_j in gdf.iterrows():\n",
    "        if i != j and municipality_i.geometry.touches(municipality_j.geometry):\n",
    "            adjacent_municipalities.append(municipality_j['GM_NAAM'])\n",
    "    adjacency_dict[municipality_i['GM_NAAM']] = adjacent_municipalities\n",
    "\n",
    "# Create a DataFrame to represent the adjacency matrix\n",
    "adjacency_matrix = pd.DataFrame(index=gdf['GM_NAAM'], columns=gdf['GM_NAAM'], dtype=int).fillna(0)\n",
    "\n",
    "# Populate the adjacency matrix\n",
    "for municipality, neighbors in adjacency_dict.items():\n",
    "    adjacency_matrix.loc[municipality, neighbors] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "### Save Adjacency Matrix ###\n",
    "#############################\n",
    "\n",
    "adjacency_matrix.to_csv('adjacency_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset COVID-19 Infections per Municipality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "### Load Dataset ###\n",
    "####################\n",
    "\n",
    "path_covid_daily_infections = r'C:\\Users\\matsu\\Desktop\\Universiteit\\MSc Statistics & Data Science\\Year 3\\Semester 1\\Mandatory Courses\\Urban Computing\\Project\\Code\\Cloned Repositories\\EpiGNN\\data\\COVID-19_aantallen_gemeente_per_dag_tm_03102021.csv'\n",
    "df_covid_daily_infections_full = pd.read_csv(path_covid_daily_infections, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "### Clean COVID-19 Infections Dataset ###\n",
    "#########################################\n",
    "\n",
    "# Remove redundant columns\n",
    "df_covid_daily_infections = df_covid_daily_infections_full[[\"Date_of_publication\", \"Municipality_code\", \"Municipality_name\",\"Province\", \"Total_reported\", \"Deceased\"]]\n",
    "\n",
    "# Check for NaNs in Total_reported and Deceased\n",
    "nan_mask_total_reported = df_covid_daily_infections['Total_reported'].isna()\n",
    "nan_mask_total_deceased = df_covid_daily_infections['Deceased'].isna()\n",
    "sum(nan_mask_total_reported), sum(nan_mask_total_deceased)\n",
    "\n",
    "# Remove those rows for which the Municipality is unknown\n",
    "df_covid_daily_infections = df_covid_daily_infections.dropna(subset=['Municipality_name'])\n",
    "nan_mask_total_municipality = df_covid_daily_infections['Municipality_name'].isna()\n",
    "sum(nan_mask_total_municipality)\n",
    "\n",
    "# Sorting the DataFrame alphabetically by Municipality name per Day\n",
    "df_covid_daily_infections = df_covid_daily_infections.sort_values(by=['Date_of_publication', 'Municipality_name'])\n",
    "df_covid_daily_infections = df_covid_daily_infections.reset_index(drop=True)\n",
    "\n",
    "# Unique Municipality Names Count (344)\n",
    "unique_names_count = df_covid_daily_infections['Municipality_name'].nunique()\n",
    "print(unique_names_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEXT** \n",
    "\n",
    "[1] Check if the adjacency matrix has the same municipalities as the dataset\n",
    "\n",
    "[2] Change .csv file to .txt file per Spain example\n",
    "\n",
    "[3] Create additional file that lists the municipalities as per the Spain example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
